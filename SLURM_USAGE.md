# Tristar Training on Digital Alliance (Fir) - Usage Guide

## ğŸ“‹ å‰ç½®å‡†å¤‡

### 1. åœ¨ Fir ä¸Šå…‹éš†é¡¹ç›®
```bash
cd $HOME
git clone https://github.com/kwc0216/tristar_autolabel.git
cd tristar_autolabel
```

### 2. ä¸Šä¼ æ•°æ®é›†
å°†ä½ çš„æ•°æ®ä¸Šä¼ åˆ° `data/tristar/` ç›®å½•ï¼š
```bash
# åœ¨æœ¬åœ°ç”µè„‘ä¸Šï¼Œä½¿ç”¨ scp ä¸Šä¼ 
scp -r data/tristar username@fir.alliancecan.ca:~/tristar_autolabel/data/

# æˆ–è€…ä½¿ç”¨ Globus ç­‰å·¥å…·ä¼ è¾“å¤§æ–‡ä»¶
```

ç¡®ä¿æ•°æ®ç»“æ„å¦‚ä¸‹ï¼š
```
data/tristar/
â”œâ”€â”€ train/
â”œâ”€â”€ val/
â””â”€â”€ test/
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ³• 1: å•ä¸ªè®­ç»ƒä»»åŠ¡ï¼ˆæ¨èç”¨äºæµ‹è¯•ï¼‰

**æ­¥éª¤ 1: ä¿®æ”¹è´¦æˆ·ä¿¡æ¯**
```bash
nano setup_and_train.sh
# å°† #SBATCH --account=def-your_account æ”¹ä¸ºä½ çš„å®é™…è´¦æˆ·
```

**æ­¥éª¤ 2: æäº¤ä»»åŠ¡**
```bash
sbatch setup_and_train.sh
```

**æ­¥éª¤ 3: æŸ¥çœ‹ä»»åŠ¡çŠ¶æ€**
```bash
squeue -u $USER
```

**æ­¥éª¤ 4: æŸ¥çœ‹æ—¥å¿—**
```bash
# æŸ¥çœ‹æ ‡å‡†è¾“å‡º
tail -f logs/slurm-<job_id>.out

# æŸ¥çœ‹é”™è¯¯è¾“å‡º
tail -f logs/slurm-<job_id>.err
```

---

### æ–¹æ³• 2: æ‰¹é‡è®­ç»ƒæ‰€æœ‰é…ç½®

**æ­¥éª¤ 1: ä¿®æ”¹è´¦æˆ·ä¿¡æ¯**
```bash
nano sbatch_train_all.sh
# ä¿®æ”¹ #SBATCH --account
```

**æ­¥éª¤ 2: æäº¤æ‰¹é‡ä»»åŠ¡**
```bash
# è¿è¡Œ 10 ä¸ª epochs
sbatch sbatch_train_all.sh 10

# æˆ–æŒ‡å®šå…¶ä»– epoch æ•°
sbatch sbatch_train_all.sh 50
```

---

### æ–¹æ³• 3: æ‰‹åŠ¨è®¾ç½®ç¯å¢ƒï¼ˆé«˜çº§ç”¨æˆ·ï¼‰

**æ­¥éª¤ 1: è®¾ç½®ç¯å¢ƒ**
```bash
bash setup_env.sh
```

**æ­¥éª¤ 2: äº¤äº’å¼è°ƒè¯•**
```bash
# ç”³è¯·äº¤äº’å¼ GPU èŠ‚ç‚¹
salloc --time=2:00:00 --mem=32G --gres=gpu:1 --account=def-your_account

# æ¿€æ´»ç¯å¢ƒ
source venv/bin/activate

# è¿è¡Œè®­ç»ƒ
python -m tristar.train --task action_classification --architecture dependent --rgb --epochs 5 --batch_size 8
```

**æ­¥éª¤ 3: æäº¤è‡ªå®šä¹‰ä»»åŠ¡**
åˆ›å»ºè‡ªå·±çš„ sbatch è„šæœ¬æˆ–ç›´æ¥æäº¤ï¼š
```bash
sbatch <<EOF
#!/bin/bash
#SBATCH --job-name=my_train
#SBATCH --account=def-your_account
#SBATCH --time=12:00:00
#SBATCH --mem=32G
#SBATCH --gres=gpu:1
#SBATCH --output=logs/my_train-%j.out

module load python/3.8 cuda/11.8 cudnn/8.6
source venv/bin/activate

python -m tristar.train \
    --task action_classification \
    --architecture dependent \
    --rgb --depth --thermal \
    --epochs 20 \
    --batch_size 16
EOF
```

---

## ğŸ“Š ç›‘æ§å’Œç®¡ç†ä»»åŠ¡

### æŸ¥çœ‹ä»»åŠ¡çŠ¶æ€
```bash
# æŸ¥çœ‹æ‰€æœ‰ä»»åŠ¡
squeue -u $USER

# æŸ¥çœ‹ç‰¹å®šä»»åŠ¡è¯¦æƒ…
scontrol show job <job_id>
```

### å–æ¶ˆä»»åŠ¡
```bash
scancel <job_id>

# å–æ¶ˆæ‰€æœ‰ä½ çš„ä»»åŠ¡
scancel -u $USER
```

### æŸ¥çœ‹ä»»åŠ¡å†å²
```bash
sacct -u $USER --format=JobID,JobName,State,Elapsed,MaxRSS,MaxVMSize
```

### å®æ—¶ç›‘æ§æ—¥å¿—
```bash
# ç›‘æ§æ ‡å‡†è¾“å‡º
tail -f logs/slurm-<job_id>.out

# ç›‘æ§è®­ç»ƒæ—¥å¿—
tail -f logs/action_classification-*/*.log
```

---

## âš™ï¸ é…ç½®è°ƒæ•´

### è°ƒæ•´ SLURM å‚æ•°

ç¼–è¾‘ `setup_and_train.sh` æˆ– `sbatch_train_all.sh`ï¼š

```bash
#SBATCH --time=24:00:00       # æ—¶é—´é™åˆ¶ï¼ˆHH:MM:SSï¼‰
#SBATCH --mem=32G             # å†…å­˜éœ€æ±‚
#SBATCH --gres=gpu:1          # GPUæ•°é‡ï¼ˆv100, a100ç­‰ï¼‰
#SBATCH --cpus-per-task=4     # CPUæ ¸å¿ƒæ•°
```

### è°ƒæ•´è®­ç»ƒå‚æ•°

ä¿®æ”¹è„šæœ¬ä¸­çš„å‚æ•°ï¼š
```bash
EPOCHS=10
BATCH_SIZE=8         # æ ¹æ®GPUæ˜¾å­˜è°ƒæ•´
LEARNING_RATE=0.0001
```

### é€‰æ‹©ä¸åŒçš„æ¨¡æ€ç»„åˆ

```bash
# åªä½¿ç”¨ RGB
python -m tristar.train --rgb --no-depth --no-thermal

# ä½¿ç”¨ RGB + Depth
python -m tristar.train --rgb --depth --no-thermal

# ä½¿ç”¨æ‰€æœ‰æ¨¡æ€
python -m tristar.train --rgb --depth --thermal
```

---

## ğŸ“ è¾“å‡ºæ–‡ä»¶ä½ç½®

è®­ç»ƒå®Œæˆåï¼Œä½ ä¼šåœ¨ä»¥ä¸‹ä½ç½®æ‰¾åˆ°è¾“å‡ºï¼š

```
logs/                                    # SLURM æ—¥å¿—
â”œâ”€â”€ slurm-<job_id>.out                  # æ ‡å‡†è¾“å‡º
â”œâ”€â”€ slurm-<job_id>.err                  # é”™è¯¯è¾“å‡º
â””â”€â”€ <config_name>_<timestamp>/          # è®­ç»ƒæ—¥å¿—
    â”œâ”€â”€ training.log                     # è¯¦ç»†è®­ç»ƒæ—¥å¿—ï¼ˆå«æŒ‡æ ‡ï¼‰
    â”œâ”€â”€ test_metrics.json                # æµ‹è¯•æŒ‡æ ‡
    â””â”€â”€ metrics/                         # CSVæ ¼å¼æŒ‡æ ‡
        â””â”€â”€ version_0/
            â””â”€â”€ metrics.csv

data/checkpoints/                        # æ¨¡å‹æ£€æŸ¥ç‚¹
â””â”€â”€ <config_name>/
    â”œâ”€â”€ epoch=00-val_loss=2.35.ckpt
    â”œâ”€â”€ epoch=05-val_loss=1.87.ckpt
    â””â”€â”€ epoch=09-val_loss=1.65.ckpt
```

---

## ğŸ”§ æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: CUDA Out of Memory
**è§£å†³æ–¹æ¡ˆ**: å‡å° batch_size
```bash
--batch_size 4  # æˆ– 2
```

### é—®é¢˜ 2: æ•°æ®è·¯å¾„é”™è¯¯
**è§£å†³æ–¹æ¡ˆ**: æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸Šä¼ åˆ°æ­£ç¡®ä½ç½®
```bash
ls -la data/tristar/train
ls -la data/tristar/val
```

### é—®é¢˜ 3: æ¨¡å—åŠ è½½å¤±è´¥
**è§£å†³æ–¹æ¡ˆ**: æ£€æŸ¥å¯ç”¨çš„æ¨¡å—ç‰ˆæœ¬
```bash
module avail cuda
module avail cudnn
module avail python
```

### é—®é¢˜ 4: ä¾èµ–å®‰è£…å¤±è´¥
**è§£å†³æ–¹æ¡ˆ**: æ‰‹åŠ¨å®‰è£…ä¾èµ–
```bash
source venv/bin/activate
pip install --upgrade pip
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install lightning torchmetrics
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

1. **å…ˆç”¨å°è§„æ¨¡æµ‹è¯•**
   ```bash
   # ä½¿ç”¨ 1 ä¸ª epoch æµ‹è¯•
   python -m tristar.train --epochs 1 --batch_size 4
   ```

2. **ä½¿ç”¨ tmux æˆ– screen**
   ```bash
   tmux new -s tristar
   # è¿è¡Œå‘½ä»¤
   # Ctrl+B, D åˆ†ç¦»ä¼šè¯
   tmux attach -t tristar  # é‡æ–°è¿æ¥
   ```

3. **å®šæœŸå¤‡ä»½ç»“æœ**
   ```bash
   # å°†ç»“æœä¸‹è½½åˆ°æœ¬åœ°
   scp -r username@fir.alliancecan.ca:~/tristar_autolabel/logs ./
   scp -r username@fir.alliancecan.ca:~/tristar_autolabel/data/checkpoints ./
   ```

4. **æŸ¥çœ‹ GPU ä½¿ç”¨æƒ…å†µ**
   ```bash
   # åœ¨äº¤äº’å¼ä¼šè¯ä¸­
   nvidia-smi
   watch -n 1 nvidia-smi  # å®æ—¶ç›‘æ§
   ```

---

## ğŸ“š æ›´å¤šèµ„æº

- [Digital Alliance Documentation](https://docs.alliancecan.ca/)
- [SLURM User Guide](https://slurm.schedmd.com/documentation.html)
- [Project GitHub](https://github.com/kwc0216/tristar_autolabel)

---

## éœ€è¦å¸®åŠ©ï¼Ÿ

å¦‚æœé‡åˆ°é—®é¢˜ï¼š
1. æ£€æŸ¥æ—¥å¿—æ–‡ä»¶ `logs/slurm-*.err`
2. æŸ¥çœ‹è®­ç»ƒæ—¥å¿— `logs/*/training.log`
3. è”ç³» Digital Alliance æ”¯æŒï¼šsupport@tech.alliancecan.ca
